

# Cognify

**Summarize & Chat with Your Files and the Web**

Cognify is a Retrieval-Augmented Generation (RAG) application that lets you create collections of documents or websites, generate AI-powered summaries, and chat with your sources â€” all while keeping answers grounded in your own data.

ğŸ¥ [Watch the demo on YouTube](https://youtu.be/gE-eSpSz69I)

---

## âœ¨ Features
- ğŸ“‚ **Collections** â€“ Organize your knowledge by project or topic.  
- ğŸ“‘ **Multiple Source Types** â€“ Add PDFs, CSVs, TXT files, or URLs into a single knowledge base.  
- ğŸ“ **AI Summaries** â€“ Generate clear, concise summaries of your sources.  
- ğŸ’¬ **Chat with Sources** â€“ Ask questions and get grounded answers with citations.  
- âš¡ **Fast & Clean UI** â€“ Built with **Next.js**, **Tailwind CSS**, and **shadcn/ui** for a modern experience.  
- ğŸ§  **OpenAI Embeddings** â€“ Uses `text-embedding-3-small` (1536 dimensions) for accurate retrieval.  
- ğŸ“¦ **Vector Search** â€“ Powered by **Qdrant**, running locally in Docker.  

---

## ğŸ–¼ï¸ Screenshots

| Collections Page | Studio â€“ Sources | Studio â€“ Summary + Chat |
|------------------|------------------|--------------------------|
| ![Collections](https://via.placeholder.com/250x150?text=Collections) | ![Sources](https://via.placeholder.com/250x150?text=Sources) | ![Chat](https://via.placeholder.com/250x150?text=Summary+Chat) |

*(replace placeholders with your actual screenshots if you want)*

---

## ğŸ› ï¸ Tech Stack
- **Frontend:** Next.js (App Router), React, Tailwind CSS v3, shadcn/ui  
- **Backend:** Next.js API routes, Node.js  
- **AI/LLM:** OpenAI API (chat + embeddings)  
- **Vector DB:** Qdrant (local Docker)  
- **Other:** pdf.js, Papaparse, Mammoth, RecursiveCharacterTextSplitter  

---

## âš™ï¸ Getting Started

### 1. Clone the repository
```bash
git clone https://github.com/yourusername/cognify.git
cd cognify

2. Install dependencies

npm install

3. Start Qdrant via Docker

npm run qdrant:up

Qdrant will be available at http://localhost:6333.

4. Create .env.local

OPENAI_API_KEY=your_openai_api_key
QDRANT_URL=http://localhost:6333
QDRANT_API_KEY=   # leave blank for local
EMBEDDING_MODEL=text-embedding-3-small

5. Run the app

npm run dev

Open http://localhost:3000.

â¸»

ğŸš€ Usage Flow
	1.	Landing Page â†’ Learn about Cognify and get started.
	2.	Collections Page â†’ Create or select a collection.
	3.	Studio
	â€¢	Add sources (Text, File, or URL).
	â€¢	View & manage sources.
	â€¢	Generate AI summaries.
	â€¢	Chat with your knowledge base.

â¸»

ğŸ“¹ Demo

â–¶ï¸ Watch the full demo on YouTube

â¸»

ğŸ¯ Why This Project?

I built Cognify to explore retrieval-augmented generation (RAG) and create a practical, personal knowledge tool.
This project demonstrates my ability to:
	â€¢	Design full-stack applications (frontend + backend).
	â€¢	Integrate LLMs with vector databases.
	â€¢	Build clean, user-friendly interfaces with shadcn/ui.
	â€¢	Deploy and work with containerized services like Qdrant.

â¸»

ğŸ“Œ Roadmap / Future Work
	â€¢	âœ… File (PDF/CSV/TXT) and URL support
	â€¢	âœ… AI summaries and chat with sources
	â€¢	â¬œ Authentication for private collections
	â€¢	â¬œ Export chat and summaries
	â€¢	â¬œ Deployment (Vercel + managed Qdrant)

â¸»

ğŸ“„ License

MIT License

---

